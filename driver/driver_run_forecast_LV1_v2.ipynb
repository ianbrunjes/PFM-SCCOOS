{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mspydell/models/PFM_root/PFM/driver/../sdpm_py_util/ocn_functions.py:20: UserWarning: The seawater library is deprecated! Please use gsw instead.\n",
      "  import seawater\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_PFM_info(): running onswell\n",
      "ocean boundary and initial conditions will be from:\n",
      "hycom\n",
      "atm forcing will be from:\n",
      "nam_nest\n",
      "Starting: driver_run_forecast_LV1: Current local Time = 2024-08-02 15:03:59.591179 UTC =  2024-08-02 22:03:59.591200+00:00\n",
      "Preparing forecast starting on  20240730\n"
     ]
    }
   ],
   "source": [
    "# -- driver_run_forecast_LV1.py  --\n",
    "# master python script to do a full LV1 forecast simulation\n",
    "\n",
    "import sys\n",
    "#import pickle\n",
    "#import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from datetime import datetime, timezone\n",
    "import gc\n",
    "import resource\n",
    "#import xarray as xr\n",
    "#import netCDF4 as nc\n",
    "\n",
    "##############\n",
    "\n",
    "sys.path.append('../sdpm_py_util')\n",
    "\n",
    "import atm_functions as atmfuns\n",
    "import ocn_functions as ocnfuns\n",
    "import grid_functions as grdfuns\n",
    "import util_functions as utlfuns \n",
    "import plotting_functions as pltfuns\n",
    "from util_functions import s_coordinate_4\n",
    "from get_PFM_info import get_PFM_info\n",
    "from make_LV1_dotin_and_SLURM import make_LV1_dotin_and_SLURM\n",
    "from run_slurm_LV1 import run_slurm_LV1\n",
    "\n",
    "\n",
    "PFM=get_PFM_info()\n",
    "\n",
    "run_type = 'forecast'\n",
    "# we will use hycom for IC and BC\n",
    "ocn_mod = PFM['ocn_model']\n",
    "print('ocean boundary and initial conditions will be from:')\n",
    "print(ocn_mod)\n",
    "# we will use nam_nest for the atm forcing\n",
    "atm_mod = PFM['atm_model']\n",
    "print('atm forcing will be from:')\n",
    "print(atm_mod)\n",
    "# we will use opendap, and netcdf to grab ocn, and atm data\n",
    "get_method = 'open_dap_nc'\n",
    "# figure out what the time is local and UTC\n",
    "start_time = datetime.now()\n",
    "utc_time = datetime.now(timezone.utc)\n",
    "year_utc = utc_time.year\n",
    "month_utc = utc_time.month\n",
    "day_utc = utc_time.day\n",
    "hour_utc = utc_time.hour\n",
    "\n",
    "print(\"Starting: driver_run_forecast_LV1: Current local Time =\", start_time, \"UTC = \",utc_time)\n",
    "\n",
    "if hour_utc < 12:\n",
    "    hour_utc=12\n",
    "    day_utc=day_utc-1  # this only works if day_utc \\neq 1\n",
    "\n",
    "yyyymmdd = \"%d%02d%02d\" % (year_utc, month_utc, day_utc)\n",
    "    \n",
    "#yyyymmdd = '20240717'\n",
    "# the hour in Z of the forecast, hycom has forecasts once per day starting at 1200Z\n",
    "hhmm='1200'\n",
    "forecastZdatestr = yyyymmdd+hhmm+'Z'   # this could be used for model output to indicate when model was initialized.\n",
    "\n",
    "yyyymmdd = '20240730'\n",
    "print(\"Preparing forecast starting on \",yyyymmdd)\n",
    "\n",
    "\n",
    "# get the ROMS grid as a dict\n",
    "RMG = grdfuns.roms_grid_to_dict(PFM['lv1_grid_file'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before getting OCN, using:\n",
      "492764\n",
      "kilobytes\n",
      "in the parallel ncks switch\n",
      "Time to get full file using parallel ncks = 89.70 sec\n",
      "Return code = 0 (0=success, 1=skipped ncks)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m use_ncks \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;66;03m# flag to get data using ncks. if =0, then a pre saved pickle file is loaded.\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_ncks \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m----> 7\u001b[0m     OCN \u001b[38;5;241m=\u001b[39m ocnfuns\u001b[38;5;241m.\u001b[39mget_ocn_data_as_dict(yyyymmdd,run_type,ocn_mod,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mncks_para\u001b[39m\u001b[38;5;124m'\u001b[39m,PFM)\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdriver_run_forecast_LV1: done with get_ocn_data_as_dict: Current time \u001b[39m\u001b[38;5;124m'\u001b[39m,datetime\u001b[38;5;241m.\u001b[39mnow() )\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter getting OCN with ncks_para, using:\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/models/PFM_root/PFM/driver/../sdpm_py_util/ocn_functions.py:333\u001b[0m, in \u001b[0;36mget_ocn_data_as_dict\u001b[0;34m(yyyymmdd, run_type, ocn_mod, get_method, PFM)\u001b[0m\n\u001b[1;32m    329\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mReturn code = \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(result) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m (0=success, 1=skipped ncks)\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    331\u001b[0m cat_fname \u001b[38;5;241m=\u001b[39m PFM[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlv1_forc_dir\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhy_cat_\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m dstr0 \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.nc\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m--> 333\u001b[0m ds \u001b[38;5;241m=\u001b[39m xr\u001b[38;5;241m.\u001b[39mopen_mfdataset(ncfiles,combine \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mby_coords\u001b[39m\u001b[38;5;124m'\u001b[39m,data_vars\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mminimal\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    335\u001b[0m enc_dict \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzlib\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcomplevel\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;241m1\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_FillValue\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;241m1e20\u001b[39m}\n\u001b[1;32m    336\u001b[0m Enc_dict \u001b[38;5;241m=\u001b[39m {vn:enc_dict \u001b[38;5;28;01mfor\u001b[39;00m vn \u001b[38;5;129;01min\u001b[39;00m ds\u001b[38;5;241m.\u001b[39mdata_vars}\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/xarray/backends/api.py:1038\u001b[0m, in \u001b[0;36mopen_mfdataset\u001b[0;34m(paths, chunks, concat_dim, compat, preprocess, engine, data_vars, coords, combine, parallel, join, attrs_file, combine_attrs, **kwargs)\u001b[0m\n\u001b[1;32m   1035\u001b[0m     open_ \u001b[38;5;241m=\u001b[39m open_dataset\n\u001b[1;32m   1036\u001b[0m     getattr_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m\n\u001b[0;32m-> 1038\u001b[0m datasets \u001b[38;5;241m=\u001b[39m [open_(p, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mopen_kwargs) \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m paths]\n\u001b[1;32m   1039\u001b[0m closers \u001b[38;5;241m=\u001b[39m [getattr_(ds, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_close\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m ds \u001b[38;5;129;01min\u001b[39;00m datasets]\n\u001b[1;32m   1040\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m preprocess \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/xarray/backends/api.py:566\u001b[0m, in \u001b[0;36mopen_dataset\u001b[0;34m(filename_or_obj, engine, chunks, cache, decode_cf, mask_and_scale, decode_times, decode_timedelta, use_cftime, concat_characters, decode_coords, drop_variables, inline_array, chunked_array_type, from_array_kwargs, backend_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m    554\u001b[0m decoders \u001b[38;5;241m=\u001b[39m _resolve_decoders_kwargs(\n\u001b[1;32m    555\u001b[0m     decode_cf,\n\u001b[1;32m    556\u001b[0m     open_backend_dataset_parameters\u001b[38;5;241m=\u001b[39mbackend\u001b[38;5;241m.\u001b[39mopen_dataset_parameters,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    562\u001b[0m     decode_coords\u001b[38;5;241m=\u001b[39mdecode_coords,\n\u001b[1;32m    563\u001b[0m )\n\u001b[1;32m    565\u001b[0m overwrite_encoded_chunks \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moverwrite_encoded_chunks\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m--> 566\u001b[0m backend_ds \u001b[38;5;241m=\u001b[39m backend\u001b[38;5;241m.\u001b[39mopen_dataset(\n\u001b[1;32m    567\u001b[0m     filename_or_obj,\n\u001b[1;32m    568\u001b[0m     drop_variables\u001b[38;5;241m=\u001b[39mdrop_variables,\n\u001b[1;32m    569\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mdecoders,\n\u001b[1;32m    570\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    571\u001b[0m )\n\u001b[1;32m    572\u001b[0m ds \u001b[38;5;241m=\u001b[39m _dataset_from_backend_dataset(\n\u001b[1;32m    573\u001b[0m     backend_ds,\n\u001b[1;32m    574\u001b[0m     filename_or_obj,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    585\u001b[0m )\n\u001b[1;32m    586\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ds\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/xarray/backends/netCDF4_.py:604\u001b[0m, in \u001b[0;36mNetCDF4BackendEntrypoint.open_dataset\u001b[0;34m(self, filename_or_obj, mask_and_scale, decode_times, concat_characters, decode_coords, drop_variables, use_cftime, decode_timedelta, group, mode, format, clobber, diskless, persist, lock, autoclose)\u001b[0m\n\u001b[1;32m    602\u001b[0m store_entrypoint \u001b[38;5;241m=\u001b[39m StoreBackendEntrypoint()\n\u001b[1;32m    603\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m close_on_error(store):\n\u001b[0;32m--> 604\u001b[0m     ds \u001b[38;5;241m=\u001b[39m store_entrypoint\u001b[38;5;241m.\u001b[39mopen_dataset(\n\u001b[1;32m    605\u001b[0m         store,\n\u001b[1;32m    606\u001b[0m         mask_and_scale\u001b[38;5;241m=\u001b[39mmask_and_scale,\n\u001b[1;32m    607\u001b[0m         decode_times\u001b[38;5;241m=\u001b[39mdecode_times,\n\u001b[1;32m    608\u001b[0m         concat_characters\u001b[38;5;241m=\u001b[39mconcat_characters,\n\u001b[1;32m    609\u001b[0m         decode_coords\u001b[38;5;241m=\u001b[39mdecode_coords,\n\u001b[1;32m    610\u001b[0m         drop_variables\u001b[38;5;241m=\u001b[39mdrop_variables,\n\u001b[1;32m    611\u001b[0m         use_cftime\u001b[38;5;241m=\u001b[39muse_cftime,\n\u001b[1;32m    612\u001b[0m         decode_timedelta\u001b[38;5;241m=\u001b[39mdecode_timedelta,\n\u001b[1;32m    613\u001b[0m     )\n\u001b[1;32m    614\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ds\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/xarray/backends/store.py:46\u001b[0m, in \u001b[0;36mStoreBackendEntrypoint.open_dataset\u001b[0;34m(self, filename_or_obj, mask_and_scale, decode_times, concat_characters, decode_coords, drop_variables, use_cftime, decode_timedelta)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28mvars\u001b[39m, attrs \u001b[38;5;241m=\u001b[39m filename_or_obj\u001b[38;5;241m.\u001b[39mload()\n\u001b[1;32m     44\u001b[0m encoding \u001b[38;5;241m=\u001b[39m filename_or_obj\u001b[38;5;241m.\u001b[39mget_encoding()\n\u001b[0;32m---> 46\u001b[0m \u001b[38;5;28mvars\u001b[39m, attrs, coord_names \u001b[38;5;241m=\u001b[39m conventions\u001b[38;5;241m.\u001b[39mdecode_cf_variables(\n\u001b[1;32m     47\u001b[0m     \u001b[38;5;28mvars\u001b[39m,\n\u001b[1;32m     48\u001b[0m     attrs,\n\u001b[1;32m     49\u001b[0m     mask_and_scale\u001b[38;5;241m=\u001b[39mmask_and_scale,\n\u001b[1;32m     50\u001b[0m     decode_times\u001b[38;5;241m=\u001b[39mdecode_times,\n\u001b[1;32m     51\u001b[0m     concat_characters\u001b[38;5;241m=\u001b[39mconcat_characters,\n\u001b[1;32m     52\u001b[0m     decode_coords\u001b[38;5;241m=\u001b[39mdecode_coords,\n\u001b[1;32m     53\u001b[0m     drop_variables\u001b[38;5;241m=\u001b[39mdrop_variables,\n\u001b[1;32m     54\u001b[0m     use_cftime\u001b[38;5;241m=\u001b[39muse_cftime,\n\u001b[1;32m     55\u001b[0m     decode_timedelta\u001b[38;5;241m=\u001b[39mdecode_timedelta,\n\u001b[1;32m     56\u001b[0m )\n\u001b[1;32m     58\u001b[0m ds \u001b[38;5;241m=\u001b[39m Dataset(\u001b[38;5;28mvars\u001b[39m, attrs\u001b[38;5;241m=\u001b[39mattrs)\n\u001b[1;32m     59\u001b[0m ds \u001b[38;5;241m=\u001b[39m ds\u001b[38;5;241m.\u001b[39mset_coords(coord_names\u001b[38;5;241m.\u001b[39mintersection(\u001b[38;5;28mvars\u001b[39m))\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/xarray/conventions.py:431\u001b[0m, in \u001b[0;36mdecode_cf_variables\u001b[0;34m(variables, attributes, concat_characters, mask_and_scale, decode_times, decode_coords, drop_variables, use_cftime, decode_timedelta)\u001b[0m\n\u001b[1;32m    424\u001b[0m stack_char_dim \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    425\u001b[0m     concat_characters\n\u001b[1;32m    426\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m v\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mS1\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    427\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m v\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    428\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m stackable(v\u001b[38;5;241m.\u001b[39mdims[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m    429\u001b[0m )\n\u001b[1;32m    430\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 431\u001b[0m     new_vars[k] \u001b[38;5;241m=\u001b[39m decode_cf_variable(\n\u001b[1;32m    432\u001b[0m         k,\n\u001b[1;32m    433\u001b[0m         v,\n\u001b[1;32m    434\u001b[0m         concat_characters\u001b[38;5;241m=\u001b[39mconcat_characters,\n\u001b[1;32m    435\u001b[0m         mask_and_scale\u001b[38;5;241m=\u001b[39mmask_and_scale,\n\u001b[1;32m    436\u001b[0m         decode_times\u001b[38;5;241m=\u001b[39mdecode_times,\n\u001b[1;32m    437\u001b[0m         stack_char_dim\u001b[38;5;241m=\u001b[39mstack_char_dim,\n\u001b[1;32m    438\u001b[0m         use_cftime\u001b[38;5;241m=\u001b[39muse_cftime,\n\u001b[1;32m    439\u001b[0m         decode_timedelta\u001b[38;5;241m=\u001b[39mdecode_timedelta,\n\u001b[1;32m    440\u001b[0m     )\n\u001b[1;32m    441\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    442\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(e)(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to decode variable \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/xarray/conventions.py:281\u001b[0m, in \u001b[0;36mdecode_cf_variable\u001b[0;34m(name, var, concat_characters, mask_and_scale, decode_times, decode_endianness, stack_char_dim, use_cftime, decode_timedelta)\u001b[0m\n\u001b[1;32m    279\u001b[0m     var \u001b[38;5;241m=\u001b[39m times\u001b[38;5;241m.\u001b[39mCFTimedeltaCoder()\u001b[38;5;241m.\u001b[39mdecode(var, name\u001b[38;5;241m=\u001b[39mname)\n\u001b[1;32m    280\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m decode_times:\n\u001b[0;32m--> 281\u001b[0m     var \u001b[38;5;241m=\u001b[39m times\u001b[38;5;241m.\u001b[39mCFDatetimeCoder(use_cftime\u001b[38;5;241m=\u001b[39muse_cftime)\u001b[38;5;241m.\u001b[39mdecode(var, name\u001b[38;5;241m=\u001b[39mname)\n\u001b[1;32m    283\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m decode_endianness \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m var\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39misnative:\n\u001b[1;32m    284\u001b[0m     var \u001b[38;5;241m=\u001b[39m variables\u001b[38;5;241m.\u001b[39mEndianCoder()\u001b[38;5;241m.\u001b[39mdecode(var)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/xarray/coding/times.py:724\u001b[0m, in \u001b[0;36mCFDatetimeCoder.decode\u001b[0;34m(self, variable, name)\u001b[0m\n\u001b[1;32m    722\u001b[0m units \u001b[38;5;241m=\u001b[39m pop_to(attrs, encoding, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munits\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    723\u001b[0m calendar \u001b[38;5;241m=\u001b[39m pop_to(attrs, encoding, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcalendar\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 724\u001b[0m dtype \u001b[38;5;241m=\u001b[39m _decode_cf_datetime_dtype(data, units, calendar, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_cftime)\n\u001b[1;32m    725\u001b[0m transform \u001b[38;5;241m=\u001b[39m partial(\n\u001b[1;32m    726\u001b[0m     decode_cf_datetime,\n\u001b[1;32m    727\u001b[0m     units\u001b[38;5;241m=\u001b[39munits,\n\u001b[1;32m    728\u001b[0m     calendar\u001b[38;5;241m=\u001b[39mcalendar,\n\u001b[1;32m    729\u001b[0m     use_cftime\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_cftime,\n\u001b[1;32m    730\u001b[0m )\n\u001b[1;32m    731\u001b[0m data \u001b[38;5;241m=\u001b[39m lazy_elemwise_func(data, transform, dtype)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/xarray/coding/times.py:182\u001b[0m, in \u001b[0;36m_decode_cf_datetime_dtype\u001b[0;34m(data, units, calendar, use_cftime)\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_decode_cf_datetime_dtype\u001b[39m(\n\u001b[1;32m    175\u001b[0m     data, units: \u001b[38;5;28mstr\u001b[39m, calendar: \u001b[38;5;28mstr\u001b[39m, use_cftime: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    176\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39mdtype:\n\u001b[1;32m    177\u001b[0m     \u001b[38;5;66;03m# Verify that at least the first and last date can be decoded\u001b[39;00m\n\u001b[1;32m    178\u001b[0m     \u001b[38;5;66;03m# successfully. Otherwise, tracebacks end up swallowed by\u001b[39;00m\n\u001b[1;32m    179\u001b[0m     \u001b[38;5;66;03m# Dataset.__repr__ when users try to view their lazily decoded array.\u001b[39;00m\n\u001b[1;32m    180\u001b[0m     values \u001b[38;5;241m=\u001b[39m indexing\u001b[38;5;241m.\u001b[39mImplicitToExplicitIndexingAdapter(indexing\u001b[38;5;241m.\u001b[39mas_indexable(data))\n\u001b[1;32m    181\u001b[0m     example_value \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate(\n\u001b[0;32m--> 182\u001b[0m         [first_n_items(values, \u001b[38;5;241m1\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m [\u001b[38;5;241m0\u001b[39m], last_item(values) \u001b[38;5;129;01mor\u001b[39;00m [\u001b[38;5;241m0\u001b[39m]]\n\u001b[1;32m    183\u001b[0m     )\n\u001b[1;32m    185\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    186\u001b[0m         result \u001b[38;5;241m=\u001b[39m decode_cf_datetime(example_value, units, calendar, use_cftime)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/xarray/core/formatting.py:77\u001b[0m, in \u001b[0;36mfirst_n_items\u001b[0;34m(array, n_desired)\u001b[0m\n\u001b[1;32m     75\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m _get_indexer_at_least_n_items(array\u001b[38;5;241m.\u001b[39mshape, n_desired, from_end\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     76\u001b[0m     array \u001b[38;5;241m=\u001b[39m array[indexer]\n\u001b[0;32m---> 77\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39masarray(array)\u001b[38;5;241m.\u001b[39mflat[:n_desired]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/xarray/core/indexing.py:484\u001b[0m, in \u001b[0;36mImplicitToExplicitIndexingAdapter.__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m    483\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__array__\u001b[39m(\u001b[38;5;28mself\u001b[39m, dtype: np\u001b[38;5;241m.\u001b[39mtyping\u001b[38;5;241m.\u001b[39mDTypeLike \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray:\n\u001b[0;32m--> 484\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39masarray(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_duck_array(), dtype\u001b[38;5;241m=\u001b[39mdtype)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/xarray/core/indexing.py:487\u001b[0m, in \u001b[0;36mImplicitToExplicitIndexingAdapter.get_duck_array\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    486\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_duck_array\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 487\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39marray\u001b[38;5;241m.\u001b[39mget_duck_array()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/xarray/core/indexing.py:551\u001b[0m, in \u001b[0;36mLazilyIndexedArray.get_duck_array\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    550\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_duck_array\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 551\u001b[0m     array \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39marray[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkey]\n\u001b[1;32m    552\u001b[0m     \u001b[38;5;66;03m# self.array[self.key] is now a numpy array when\u001b[39;00m\n\u001b[1;32m    553\u001b[0m     \u001b[38;5;66;03m# self.array is a BackendArray subclass\u001b[39;00m\n\u001b[1;32m    554\u001b[0m     \u001b[38;5;66;03m# and self.key is BasicIndexer((slice(None, None, None),))\u001b[39;00m\n\u001b[1;32m    555\u001b[0m     \u001b[38;5;66;03m# so we need the explicit check for ExplicitlyIndexed\u001b[39;00m\n\u001b[1;32m    556\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(array, ExplicitlyIndexed):\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/xarray/backends/netCDF4_.py:100\u001b[0m, in \u001b[0;36mNetCDF4ArrayWrapper.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, key):\n\u001b[0;32m--> 100\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m indexing\u001b[38;5;241m.\u001b[39mexplicit_indexing_adapter(\n\u001b[1;32m    101\u001b[0m         key, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshape, indexing\u001b[38;5;241m.\u001b[39mIndexingSupport\u001b[38;5;241m.\u001b[39mOUTER, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem\n\u001b[1;32m    102\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/xarray/core/indexing.py:858\u001b[0m, in \u001b[0;36mexplicit_indexing_adapter\u001b[0;34m(key, shape, indexing_support, raw_indexing_method)\u001b[0m\n\u001b[1;32m    836\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Support explicit indexing by delegating to a raw indexing method.\u001b[39;00m\n\u001b[1;32m    837\u001b[0m \n\u001b[1;32m    838\u001b[0m \u001b[38;5;124;03mOuter and/or vectorized indexers are supported by indexing a second time\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    855\u001b[0m \u001b[38;5;124;03mIndexing result, in the form of a duck numpy-array.\u001b[39;00m\n\u001b[1;32m    856\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    857\u001b[0m raw_key, numpy_indices \u001b[38;5;241m=\u001b[39m decompose_indexer(key, shape, indexing_support)\n\u001b[0;32m--> 858\u001b[0m result \u001b[38;5;241m=\u001b[39m raw_indexing_method(raw_key\u001b[38;5;241m.\u001b[39mtuple)\n\u001b[1;32m    859\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m numpy_indices\u001b[38;5;241m.\u001b[39mtuple:\n\u001b[1;32m    860\u001b[0m     \u001b[38;5;66;03m# index the loaded np.ndarray\u001b[39;00m\n\u001b[1;32m    861\u001b[0m     result \u001b[38;5;241m=\u001b[39m NumpyIndexingAdapter(result)[numpy_indices]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/xarray/backends/netCDF4_.py:111\u001b[0m, in \u001b[0;36mNetCDF4ArrayWrapper._getitem\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    108\u001b[0m     getitem \u001b[38;5;241m=\u001b[39m operator\u001b[38;5;241m.\u001b[39mgetitem\n\u001b[1;32m    110\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 111\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdatastore\u001b[38;5;241m.\u001b[39mlock:\n\u001b[1;32m    112\u001b[0m         original_array \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_array(needs_lock\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    113\u001b[0m         array \u001b[38;5;241m=\u001b[39m getitem(original_array, key)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/xarray/backends/locks.py:163\u001b[0m, in \u001b[0;36mCombinedLock.__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__enter__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m lock \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlocks:\n\u001b[0;32m--> 163\u001b[0m         lock\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__enter__\u001b[39m()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/dask/utils.py:1338\u001b[0m, in \u001b[0;36mSerializableLock.__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1337\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__enter__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m-> 1338\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlock\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__enter__\u001b[39m()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print('before getting OCN, using:')\n",
    "print(resource.getrusage(resource.RUSAGE_SELF).ru_maxrss)\n",
    "print('kilobytes')\n",
    "\n",
    "use_ncks = 1 # flag to get data using ncks. if =0, then a pre saved pickle file is loaded.\n",
    "if use_ncks == 1:\n",
    "    OCN = ocnfuns.get_ocn_data_as_dict(yyyymmdd,run_type,ocn_mod,'ncks_para',PFM)\n",
    "    print('driver_run_forecast_LV1: done with get_ocn_data_as_dict: Current time ',datetime.now() )\n",
    "    print('after getting OCN with ncks_para, using:')\n",
    "    print(resource.getrusage(resource.RUSAGE_SELF).ru_maxrss)\n",
    "    print('kilobytes')\n",
    "else:\n",
    "    save_ocn = 0 # if 0, this loads the pickle file. if 1, it saves the pickle file\n",
    "    import pickle\n",
    "    # save the OCN dict so that we can restart the python session\n",
    "    # and not have to worry about opendap timing out\n",
    "    fnout='/scratch/PFM_Simulations/LV1_Forecast/Forc/ocn_dict_file_2024-07-29T12:00.pkl'\n",
    "    if save_ocn == 1:\n",
    "        with open(fnout,'wb') as fp:\n",
    "            pickle.dump(OCN,fp)\n",
    "            print('OCN dict saved with pickle')\n",
    "    else:\n",
    "        with open(fnout,'rb') as fp:\n",
    "            OCN = pickle.load(fp)\n",
    "            print('OCN dict loaded with pickle')\n",
    "            print('after getting OCN from file, using:')\n",
    "            print(resource.getrusage(resource.RUSAGE_SELF).ru_maxrss)\n",
    "            print('kilobytes')\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before gc.collect and getting OCN_R, using:\n",
      "1809016\n",
      "kilobytes\n",
      "after gc.collect and before OCN_R, using:\n",
      "1809016\n",
      "kilobytes\n",
      "starting: ocnfuns.hycom_to_roms_latlon(OCN,RMG)\n",
      "before interp to roms grid, using:\n",
      "1809016\n",
      "kilobytes\n",
      "doing:\n",
      "zeta\n",
      "doing:\n",
      "temp\n",
      "doing:\n",
      "salt\n",
      "doing:\n",
      "u\n",
      "doing:\n",
      "v\n",
      "before rotating urm, using:\n",
      "5497260\n",
      "kilobytes\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "print('before gc.collect and getting OCN_R, using:')\n",
    "print(resource.getrusage(resource.RUSAGE_SELF).ru_maxrss)\n",
    "print('kilobytes')\n",
    "gc.collect()\n",
    "print('after gc.collect and before OCN_R, using:')\n",
    "print(resource.getrusage(resource.RUSAGE_SELF).ru_maxrss)\n",
    "print('kilobytes')\n",
    "# put the ocn data on the roms grid\n",
    "print('starting: ocnfuns.hycom_to_roms_latlon(OCN,RMG)')\n",
    "OCN_R  = ocnfuns.hycom_to_roms_latlon(OCN,RMG)\n",
    "print('driver_run_forecast_LV1: done with hycom_to_roms_latlon')\n",
    "# add OCN + OCN_R plotting function here !!!\n",
    "\n",
    "del OCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21, 40, 390, 252)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(OCN_R['urm']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %%\n",
    "# get the OCN_IC dictionary\n",
    "OCN_IC = ocnfuns.ocn_r_2_ICdict(OCN_R,RMG)\n",
    "print('driver_run_forecast_LV1: done with ocn_r_2_ICdict')\n",
    "# add OCN_IC.nc plotting function here !!!!\n",
    "ic_file_out = PFM['lv1_forc_dir'] + '/' + PFM['lv1_ini_file']\n",
    "ocnfuns.ocn_roms_IC_dict_to_netcdf(OCN_IC, ic_file_out)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# get the OCN_BC dictionary\n",
    "bc_file_out = PFM['lv1_forc_dir'] + '/' + PFM['lv1_bc_file']\n",
    "OCN_BC = ocnfuns.ocn_r_2_BCdict(OCN_R,RMG)\n",
    "print('driver_run_forecast_LV1: done with ocn_r_2_BCdict')\n",
    "ocnfuns.ocn_roms_BC_dict_to_netcdf(OCN_BC, bc_file_out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting atm forecast for:\n",
      "[datetime.datetime(2024, 7, 29, 12, 0)\n",
      " datetime.datetime(2024, 7, 29, 15, 0)\n",
      " datetime.datetime(2024, 7, 29, 18, 0)\n",
      " datetime.datetime(2024, 7, 29, 21, 0)\n",
      " datetime.datetime(2024, 7, 30, 0, 0) datetime.datetime(2024, 7, 30, 3, 0)\n",
      " datetime.datetime(2024, 7, 30, 6, 0) datetime.datetime(2024, 7, 30, 9, 0)\n",
      " datetime.datetime(2024, 7, 30, 12, 0)\n",
      " datetime.datetime(2024, 7, 30, 15, 0)\n",
      " datetime.datetime(2024, 7, 30, 18, 0)\n",
      " datetime.datetime(2024, 7, 30, 21, 0)\n",
      " datetime.datetime(2024, 7, 31, 0, 0) datetime.datetime(2024, 7, 31, 3, 0)\n",
      " datetime.datetime(2024, 7, 31, 6, 0) datetime.datetime(2024, 7, 31, 9, 0)\n",
      " datetime.datetime(2024, 7, 31, 12, 0)\n",
      " datetime.datetime(2024, 7, 31, 15, 0)\n",
      " datetime.datetime(2024, 7, 31, 18, 0)\n",
      " datetime.datetime(2024, 7, 31, 21, 0) datetime.datetime(2024, 8, 1, 0, 0)]\n"
     ]
    }
   ],
   "source": [
    "# make a switch to see if this file exists. If it exists, we don't need to run the code in this block\n",
    "# first the atm data\n",
    "# get the data as a dict\n",
    "# need to specify hhmm because nam forecast are produced at 6 hr increments\n",
    "ATM = atmfuns.get_atm_data_as_dict(yyyymmdd,hhmm,run_type,atm_mod,'open_dap_nc',PFM)\n",
    "# put in a function to check to make sure that all the data is good\n",
    "# put in a function to plot the raw atm data if we want to\n",
    "\n",
    "\n",
    "# plot some stuff\n",
    "pltfuns.plot_atm_fields(ATM, RMG, PFM)\n",
    "print('done with plotting ATM fields')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done with: atmfuns.get_atm_data_on_roms_grid(ATM,RMG)\n"
     ]
    }
   ],
   "source": [
    "# put the atm data on the roms grid, and rotate the velocities\n",
    "# everything in this dict turn into the atm.nc file\n",
    "\n",
    "ATM_R  = atmfuns.get_atm_data_on_roms_grid(ATM,RMG)\n",
    "print('done with: atmfuns.get_atm_data_on_roms_grid(ATM,RMG)')\n",
    "# all the fields plotted with the data on roms grid\n",
    "\n",
    "\n",
    "pltfuns.plot_all_fields_in_one(ATM, ATM_R, RMG, PFM)\n",
    "print('done with: pltfuns.plot_all_fields_in_one(ATM, ATM_R, RMG, PFM)')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "driver_run_forcast_LV1: saving ATM file to /scratch/PFM_Simulations/LV1_Forecast/Forc/LV1_ATM_FORCING.nc\n",
      "<xarray.Dataset>\n",
      "Dimensions:     (tair_time: 21, er: 390, xr: 253, pair_time: 21, qair_time: 21,\n",
      "                 wind_time: 21, rain_time: 21, srf_time: 21, lrf_time: 21,\n",
      "                 time: 21)\n",
      "Coordinates:\n",
      "    lat         (er, xr) float64 28.52 28.53 28.54 28.55 ... 36.38 36.39 36.39\n",
      "    lon         (er, xr) float64 -120.3 -120.2 -120.2 ... -118.8 -118.8 -118.8\n",
      "    ocean_time  (time) float64 9.342e+03 9.342e+03 ... 9.344e+03 9.344e+03\n",
      "  * tair_time   (tair_time) float64 9.342e+03 9.342e+03 ... 9.344e+03 9.344e+03\n",
      "  * pair_time   (pair_time) float64 9.342e+03 9.342e+03 ... 9.344e+03 9.344e+03\n",
      "  * qair_time   (qair_time) float64 9.342e+03 9.342e+03 ... 9.344e+03 9.344e+03\n",
      "  * wind_time   (wind_time) float64 9.342e+03 9.342e+03 ... 9.344e+03 9.344e+03\n",
      "  * rain_time   (rain_time) float64 9.342e+03 9.342e+03 ... 9.344e+03 9.344e+03\n",
      "  * srf_time    (srf_time) float64 9.342e+03 9.342e+03 ... 9.344e+03 9.344e+03\n",
      "  * lrf_time    (lrf_time) float64 9.342e+03 9.342e+03 ... 9.344e+03 9.344e+03\n",
      "Dimensions without coordinates: er, xr, time\n",
      "Data variables:\n",
      "    Tair        (tair_time, er, xr) float64 19.58 19.57 19.56 ... 35.78 35.69\n",
      "    Pair        (pair_time, er, xr) float64 1.016e+03 1.016e+03 ... 1.013e+03\n",
      "    Qair        (qair_time, er, xr) float64 87.58 87.68 87.98 ... 26.36 26.93\n",
      "    Uwind       (wind_time, er, xr) float64 -1.449 -1.431 -1.41 ... 2.082 2.099\n",
      "    Vwind       (wind_time, er, xr) float64 -6.866 -6.872 ... -2.049 -2.083\n",
      "    rain        (rain_time, er, xr) float64 0.0 0.0 0.0 0.0 ... 0.0 0.0 0.0 0.0\n",
      "    swrad       (srf_time, er, xr) float64 0.0 0.0 0.0 0.0 ... 470.7 471.5 471.1\n",
      "    lwrad       (lrf_time, er, xr) float64 -4.573 -4.418 ... -168.5 -168.4\n",
      "    lwrad_down  (lrf_time, er, xr) float64 399.4 399.5 399.5 ... 348.1 347.6\n",
      "Attributes:\n",
      "    type:       atmospheric forcing file fields for surface fluxes\n",
      "    time info:  ocean time is from 1999/01/01 00:00:00\n",
      "driver_run_forecast_LV1:  done with writing ATM file, Current time  2024-07-31 12:29:56.354362\n",
      "done with pltfuns.load_and_plot_atm(PFM)\n"
     ]
    }
   ],
   "source": [
    "# output a netcdf file of ATM_R\n",
    "# make the atm .nc file here.\n",
    "# fn_out is the name of the atm.nc file used by roms\n",
    "fn_out = PFM['lv1_forc_dir'] + '/' + PFM['lv1_atm_file'] # LV1 atm forcing filename\n",
    "print('driver_run_forcast_LV1: saving ATM file to ' + fn_out)\n",
    "atmfuns.atm_roms_dict_to_netcdf(ATM_R,fn_out)\n",
    "print('driver_run_forecast_LV1:  done with writing ATM file, Current time ', datetime.now())\n",
    "# put in a function to plot the atm.nc file if we want to\n",
    "pltfuns.load_and_plot_atm(RMG, PFM)\n",
    "print('done with pltfuns.load_and_plot_atm(PFM)')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print('driver_run_forecast_LV1:  now make .in and .sb files')\n",
    "\n",
    "pfm_driver_src_dir = os.getcwd()\n",
    "os.chdir('../sdpm_py_util')\n",
    "make_LV1_dotin_and_SLURM( PFM )\n",
    "\n",
    "# run command will be\n",
    "run_slurm_LV1(PFM)\n",
    "\n",
    "os.chdir(pfm_driver_src_dir)\n",
    "\n",
    "\n",
    "# postprocess figure generation\n",
    "# plot fields from his.nc\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to get full file using ncks = 1517.43 sec\n",
      "Return code = 0 (0=success, 1=skipped ncks)\n",
      "driver_run_forecast_LV1: done with get_ocn_data_as_dict: Current time  2024-07-31 13:19:42.922055\n"
     ]
    }
   ],
   "source": [
    "# ========================================\n",
    "# OLD and testing stuff is below this line\n",
    "# ========================================\n",
    "\n",
    "# note, this function is hard wired to return 2.5 days of data\n",
    "# also note that the first time of this data is yyyymmdd 12:00Z\n",
    "# so we grab nam atm forecast data starting at this hour too.\n",
    "OCN = ocnfuns.get_ocn_data_as_dict(yyyymmdd,run_type,ocn_mod,'ncks',PFM)\n",
    "print('driver_run_forecast_LV1: done with get_ocn_data_as_dict: Current time ',datetime.now() )\n",
    "# add OCN plotting function here !!!!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[28.         28.04000092 28.07999992 28.12000084 28.15999985 28.20000076\n",
      " 28.23999977 28.28000069 28.31999969 28.36000061 28.39999962 28.44000053\n",
      " 28.47999954 28.52000046 28.55999947 28.60000038 28.63999939 28.68000031\n",
      " 28.71999931 28.76000023 28.79999924 28.84000015 28.87999916 28.92000008\n",
      " 28.95999908 29.         29.04000092 29.07999992 29.12000084 29.15999985\n",
      " 29.20000076 29.23999977 29.28000069 29.31999969 29.36000061 29.39999962\n",
      " 29.44000053 29.47999954 29.52000046 29.55999947 29.60000038 29.63999939\n",
      " 29.68000031 29.71999931 29.76000023 29.79999924 29.84000015 29.87999916\n",
      " 29.92000008 29.95999908 30.         30.04000092 30.07999992 30.12000084\n",
      " 30.15999985 30.20000076 30.23999977 30.28000069 30.31999969 30.36000061\n",
      " 30.39999962 30.44000053 30.47999954 30.52000046 30.55999947 30.60000038\n",
      " 30.63999939 30.68000031 30.71999931 30.76000023 30.79999924 30.84000015\n",
      " 30.87999916 30.92000008 30.95999908 31.         31.04000092 31.07999992\n",
      " 31.12000084 31.15999985 31.20000076 31.23999977 31.28000069 31.31999969\n",
      " 31.36000061 31.39999962 31.44000053 31.47999954 31.52000046 31.55999947\n",
      " 31.60000038 31.63999939 31.68000031 31.71999931 31.76000023 31.79999924\n",
      " 31.84000015 31.87999916 31.92000008 31.95999908 32.         32.04000092\n",
      " 32.08000183 32.11999893 32.15999985 32.20000076 32.24000168 32.27999878\n",
      " 32.31999969 32.36000061 32.40000153 32.43999863 32.47999954 32.52000046\n",
      " 32.56000137 32.59999847 32.63999939 32.68000031 32.72000122 32.75999832\n",
      " 32.79999924 32.84000015 32.88000107 32.91999817 32.95999908 33.\n",
      " 33.04000092 33.08000183 33.11999893 33.15999985 33.20000076 33.24000168\n",
      " 33.27999878 33.31999969 33.36000061 33.40000153 33.43999863 33.47999954\n",
      " 33.52000046 33.56000137 33.59999847 33.63999939 33.68000031 33.72000122\n",
      " 33.75999832 33.79999924 33.84000015 33.88000107 33.91999817 33.95999908\n",
      " 34.         34.04000092 34.08000183 34.11999893 34.15999985 34.20000076\n",
      " 34.24000168 34.27999878 34.31999969 34.36000061 34.40000153 34.43999863\n",
      " 34.47999954 34.52000046 34.56000137 34.59999847 34.63999939 34.68000031\n",
      " 34.72000122 34.75999832 34.79999924 34.84000015 34.88000107 34.91999817\n",
      " 34.95999908 35.         35.04000092 35.08000183 35.11999893 35.15999985\n",
      " 35.20000076 35.24000168 35.27999878 35.31999969 35.36000061 35.40000153\n",
      " 35.43999863 35.47999954 35.52000046 35.56000137 35.59999847 35.63999939\n",
      " 35.68000031 35.72000122 35.75999832 35.79999924 35.84000015 35.88000107\n",
      " 35.91999817 35.95999908 36.         36.04000092 36.08000183 36.11999893\n",
      " 36.15999985 36.20000076 36.24000168 36.27999878 36.31999969 36.36000061\n",
      " 36.40000153 36.43999863 36.47999954 36.52000046 36.56000137 36.59999847\n",
      " 36.63999939 36.68000031 36.72000122 36.75999832 36.79999924 36.84000015\n",
      " 36.88000107 36.91999817 36.95999908 37.        ]\n"
     ]
    }
   ],
   "source": [
    "import xarray as xr\n",
    "\n",
    "fn='/scratch/PFM_Simulations/LV1_Forecast/Forc/hy_cat_2024-07-29T12:00.nc'\n",
    "ds = xr.open_dataset(fn)\n",
    "print(ds.lat.values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "tstr = \"2024-07-30T12:00\"\n",
    "ffname = \"hy_\" + tstr + \"_*.nc\"\n",
    "full_fns_out = PFM['lv1_forc_dir'] + \"/\" + ffname\n",
    "ncfiles = glob.glob(full_fns_out)\n",
    "cat_fname = PFM['lv1_forc_dir'] + '/' + 'hy_cat_' + tstr + '.nc'\n",
    "\n",
    "print(ncfiles)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-30T12:00\n",
      "2024-07-30 12:00:00\n",
      "2024-08-02 00:00:00\n",
      "2024-08-02T00:00\n"
     ]
    }
   ],
   "source": [
    "from datetime import timedelta\n",
    "\n",
    "tstr = '2024-07-30T12:00'\n",
    "print(tstr)\n",
    "t1 = datetime.strptime(tstr,\"%Y-%m-%dT%H:%M\")\n",
    "t2 = t1 + 2.5 * timedelta(days=1)\n",
    "print(t1)\n",
    "print(t2)\n",
    "t2str = t2.strftime(\"%Y-%m-%dT%H:%M\")\n",
    "print(t2str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a block of code to use ncks...\n",
    "import time\n",
    "import subprocess\n",
    "\n",
    "vstr = 'surf_el,water_temp,salinity,water_u,water_v,depth'\n",
    "\n",
    "# make the ocn IC and BC .nc files here\n",
    "# fn*_out are the names of the the IC.nc and BC.nc roms files\n",
    "lv1_forc_dir = PFM['lv1_forc_dir']   #'/Users/mspydell/research/FF2024/models/SDPM_mss/atm_stuff/ocn_test_IC_file.nc'\n",
    "full_fn_out = lv1_forc_dir + '/hycom_test_mss.nc'\n",
    "\n",
    "west =  PFM['latlonbox'][2]+360.0\n",
    "east =  PFM['latlonbox'][3]+360.0\n",
    "south = PFM['latlonbox'][0]\n",
    "north = PFM['latlonbox'][1]\n",
    "\n",
    "yyyy = yyyymmdd[0:4]\n",
    "mm = yyyymmdd[4:6]\n",
    "dd = yyyymmdd[6:8]\n",
    "\n",
    "# time limits\n",
    "dstr0 = yyyy + '-' + mm + '-' + dd + 'T12:00'\n",
    "dstr1 = yyyy + '-' + mm + '-' + str( int(dd) + 1 ) + 'T00:00'\n",
    "\n",
    "url='https://tds.hycom.org/thredds/dodsC/GLBy0.08/expt_93.0/FMRC/runs/' \n",
    "url2 = 'GLBy0.08_930_FMRC_RUN_' + yyyy + '-' + mm + '-' + dd + 'T12:00:00Z' \n",
    "url3 = url + url2\n",
    "cmd_list = ['ncks',\n",
    "    '-d', 'time,'+dstr0+','+dstr1,\n",
    "    '-d', 'lon,'+str(west)+','+str(east),\n",
    "    '-d', 'lat,'+str(south)+','+str(north),\n",
    "    '-v', vstr,\n",
    "    url3 ,\n",
    "    '-4', '-O', full_fn_out]\n",
    "\n",
    "print(cmd_list)\n",
    "\n",
    "# run ncks\n",
    "tt0 = time.time()\n",
    "ret1 = subprocess.call(cmd_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9340.5   9340.625 9340.75  9340.875 9341.   ]\n"
     ]
    }
   ],
   "source": [
    "import xarray as xr\n",
    "from datetime import timedelta\n",
    "\n",
    "ds = xr.open_dataset(full_fn_out)\n",
    "#print(ds)\n",
    "\n",
    "t_hy = ds.time\n",
    "t_ref = PFM['modtime0']\n",
    "\n",
    "dt_day = (t_hy - np.datetime64(t_ref))  / np.timedelta64(1,'D')\n",
    "\n",
    "print(dt_day.values)\n",
    "#print(t_hy[0]-t_ref)\n",
    "\n",
    "\n",
    "#t_hy2 = datetime(t_hy)\n",
    "\n",
    "#t_ref?\n",
    "#deltat = t_hy - t_ref\n",
    "\n",
    "#print(deltat)\n",
    "\n",
    "\n",
    "#print(t_hy)\n",
    "#print(t_ref)\n",
    "      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "zz=np.random.randn(2,3,4,5)\n",
    "dum = zz[1,2,:,:]\n",
    "ang = np.random.randn(4,5)\n",
    "ang2 = np.tile(ang,(2,3,1,1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
