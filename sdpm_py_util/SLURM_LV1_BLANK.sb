#!/bin/bash

# job name
#SBATCH --job-name=L1I06J18

# slurm job output file
#SBATCH --output=%j.out

# partition of nodes to use
#SBATCH --partition=fast

# number of MPI tasks
#SBATCH --ntasks=$np$

# number of cpus for a task
#SBATCH --cpus-per-task=1
#SBATCH --mem=128G

# number of nodes to use
#SBATCH --nodes=3

# number of tasks per node
#SBATCH --ntasks-per-node=36

module purge

module load gcc/11.2.0
module load openmpi/gcc/64/4.1.5
module load hdf5/1.14.3
module load netcdf/mpicc/4.8.1
module load slurm

export LD_LIBRARY_PATH=/cm/shared/apps/netcdf/gcc/64/4.8.1/lib:$LD_LIBRARY_PATH

MYAPP=$lv1_run_dir$

mpirun -v -np $np$  $MYAPP  $lv1_infile$  > $lv_outfile$

